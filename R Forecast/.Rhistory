emb_dim <- 20  # Embedding dimension
# Create input layers for current categorical values
input_player_id <- layer_input(shape = c(1), dtype = "int32", name = "input_player_id")
input_tID <- layer_input(shape = c(1), dtype = "int32", name = "input_tID")
input_oID <- layer_input(shape = c(1), dtype = "int32", name = "input_oID")
input_hID <- layer_input(shape = c(1), dtype = "int32", name = "input_hID")
embedding_player_id <- input_player_id %>%
layer_embedding(input_dim = num_players + 1, output_dim = emb_dim, mask_zero = TRUE) %>%
layer_flatten()
embedding_tID <- input_tID %>%
layer_embedding(input_dim = num_teams + 1, output_dim = emb_dim, mask_zero = TRUE) %>%
layer_flatten()
embedding_oID <- input_oID %>%
layer_embedding(input_dim = num_opponents + 1, output_dim = emb_dim, mask_zero = TRUE) %>%
layer_flatten()
# For hID, convert to float32 to match types
input_hID_flat <- input_hID %>%
layer_lambda(function(x) tf$cast(x, tf$float32)) %>%
layer_flatten()
# Merge categorical branch
cat_merged <- layer_concatenate(list(embedding_player_id, embedding_tID, embedding_oID, input_hID_flat)) %>%
layer_dense(units = 16, activation = "relu")
# Numerical branch: input for rolling window data
input_seq <- layer_input(shape = c(ws, length(numF)), name = "input_seq")
lstm_branch <- input_seq %>%
layer_lstm(units = 64, return_sequences = FALSE) %>%
layer_dropout(rate = 0.2)
# Merge both branches and build the output
merged <- layer_concatenate(list(lstm_branch, cat_merged))
dense_layer <- merged %>% layer_dense(units = 32, activation = "relu")
output <- dense_layer %>% layer_dense(units = 1, activation = "linear")
# Build and compile the model
model <- keras_model(
inputs = list(input_seq, input_player_id, input_tID, input_oID, input_hID),
outputs = output,
name = "fwd_lstm_model"
)
model %>% compile(
optimizer = optimizer_adam(),
loss = "mse",
metrics = metrics_regression,
run_eagerly = TRUE
)
summary(model)
# Filepath for saving the BEST weights (unique for each position)
weights_filepath_fwd <- "R Forecast/best_fwd_weights.hdf5"
cat("Will save best FWD weights to:", weights_filepath_fwd, "\n")
# 1. Early Stopping Callback
early_stopping <- callback_early_stopping(
monitor = "val_loss",       # Monitor validation loss
patience = num_patience,              # Stop after 10 epochs of no improvement
restore_best_weights = TRUE # Optional but good: restores weights from the best epoch at the end of training
# Note: Checkpoint callback is the primary saver here.
)
# 2. Model Checkpoint Callback (to save best weights)
model_checkpoint <- callback_model_checkpoint(
filepath = weights_filepath_fwd, # Path defined above
monitor = "val_loss",           # Monitor the same metric as early stopping
save_best_only = TRUE,          # IMPORTANT: Only save when val_loss improves
save_weights_only = TRUE,       # IMPORTANT: Save ONLY the weights, not the whole model
mode = "min",                   # We want to minimize loss
verbose = 1                     # Optional: print message when weights are saved
)
reduce_lr <- callback_reduce_lr_on_plateau(
monitor = "val_loss",  # Monitor validation loss (same as early stopping)
factor = 0.2,          # Reduce LR to 20% of its current value (lr * factor)
patience = 5,           # Reduce LR if val_loss doesn't improve for 5 epochs
min_lr = 1e-6,         # Don't reduce the LR below this value
verbose = 1            # Print a message when LR is reduced
)
# Store scaling factors NOW (before potential errors during training)
# Ensure mu, sigma, and numF (Lasso selected) are correctly captured from the FWD scaling steps
scaling_factors$fwd <- list(
mu = mu,         # Mean of FWD target used for scaling
sigma = sigma,   # SD of FWD target used for scaling
numF = numF      # Vector of Lasso-selected numerical feature names for FWD
)
cat("FWD scaling factors stored.\n")
#============================
# 8. Train the Model
#============================
cat("Starting FWD model training...\n")
history <- model %>% fit(
x = list(
input_seq = Xnum_train,
input_player_id = cat_player_id_train,
input_tID = cat_tID_train,
input_oID = cat_oID_train,
input_hID = cat_hID_train
),
y = y_train,
epochs = epoker,          # Max epochs
batch_size = 64,          # Try increasing batch size (e.g., 64 or 128) for speed
validation_data = list(
list(
input_seq = Xnum_val,
input_player_id = cat_player_id_val,
input_tID = cat_tID_val,
input_oID = cat_oID_val,
input_hID = cat_hID_val
),
y_val
),
# ADD THE CALLBACKS HERE
callbacks = list(early_stopping, model_checkpoint, reduce_lr)
)
cat("FWD model training finished.\n")
#============================
# 9. Generate Predictions & Invert Scaling on Validation Set
#============================
# Use the validation set for predictions
pred_all <- model %>% predict(
list(
input_seq = Xnum_val,
input_player_id = cat_player_id_val,
input_tID = cat_tID_val,
input_oID = cat_oID_val,
input_hID = cat_hID_val
)
)
# Build a predictions table using the validation row IDs
preds_fwd <- tibble(
row_id = val_row_ids,  # row IDs corresponding to the validation set
predicted_total_points_scaled = as.vector(pred_all),
actual_total_points_scaled = as.vector(y_val)
) %>%
mutate(
predicted_total_points = predicted_total_points_scaled * sigma + mu,
actual_total_points = actual_total_points_scaled * sigma + mu
)
preds_fwd <- preds_fwd %>%
left_join(unscaled_fwd, by = "row_id") # Use unscaled_mid
glimpse(preds_fwd)
plot(history)
history_df_fwd <- data.frame(history)
glimpse(history_df_fwd)
# Store FWD model and scaling factors
model_list$fwd <- model
cat("FWD model and scaling factors stored.\n")
# Clean up validation predictions (select essential columns)
# Note: The join in cell f2292df7 uses 'fwd' (scaled) then 'unscaled_fwd'.
preds_fwd_clean <- preds_fwd %>%
select(row_id, GW , player_id , name, position, team, # Identifiers from unscaled_fwd join
actual_total_points, predicted_total_points, value)
# After training, evaluate the model on validation data with all metrics
model_evaluation <- model %>% evaluate(
x = list(
input_seq = Xnum_val,
input_player_id = cat_player_id_val,
input_tID = cat_tID_val,
input_oID = cat_oID_val,
input_hID = cat_hID_val
),
y = y_val,
verbose = 1
)
# Print the evaluation results (metrics specified during compilation)
print(model_evaluation)
# Combine results by position
validation_metrics$fwd <- model_list$fwd %>% evaluate(
x = list(
input_seq = Xnum_val,
input_player_id = cat_player_id_val,
input_tID = cat_tID_val,
input_oID = cat_oID_val,
input_hID = cat_hID_val
),
y = y_val
)
glimpse(preds_gk)
glimpse(preds_def)
glimpse(preds_mid)
glimpse(preds_fwd)
# filepath: c:\Users\peram\Documents\test\R Forecast\prognose-modell.ipynb
# Combine the CLEANED validation predictions
validation_results_df <- bind_rows(
preds_gk_clean,
preds_def_clean,
preds_mid_clean,
preds_fwd_clean
) %>%
arrange(player_id, GW)
glimpse(validation_results_df)
# Keep the original detailed forecast df as well (optional)
forecastdf_detailed <- bind_rows(preds_gk, preds_def, preds_mid, preds_fwd)
cat("Clean and detailed validation results combined.\n")
# Create metrics comparison dataframe
metrics_df <- data.frame(
metric = names(validation_metrics$gk),
GK = unlist(validation_metrics$gk),
DEF = unlist(validation_metrics$def),
MID = unlist(validation_metrics$mid),
FWD = unlist(validation_metrics$fwd)
)
metrics_df
# Export CLEAN validation results
write_csv(validation_results_df, "Validation_Predictions_Clean.csv")
cat("Clean validation predictions saved to Validation_Predictions_Clean.csv\n")
# Export DETAILED validation results (original behavior, renamed file)
write_csv(forecastdf_detailed, "Validation_Predictions_Detailed.csv")
cat("Detailed validation predictions saved to Validation_Predictions_Detailed.csv\n")
# Funksjon som henter fra api
# Function to get fixtures from FPL API
get_fpl_fixtures <- function() {
# Make API request
response <- GET("https://fantasy.premierleague.com/api/fixtures/")
# Check if request was successful
if (http_status(response)$category != "Success") {
stop("Failed to fetch fixtures from FPL API. Status code: ", status_code(response))
}
# Parse JSON response
fixtures_json <- content(response, "text", encoding = "UTF-8")
fixtures_data <- fromJSON(fixtures_json, flatten = TRUE)
# Basic transformation to required format
formatted_fixtures <- tibble(
GW = fixtures_data$event,
home_team_id = fixtures_data$team_h,
away_team_id = fixtures_data$team_a,
kickoff_time = fixtures_data$kickoff_time
) %>%
# Filter out fixtures with no scheduled gameweek (NULL or NA values)
filter(!is.na(GW)) %>%
# Create the same format as your previous code
transmute(
GW = GW,
# Create a row for home team
team_id = home_team_id,
opponent_id = away_team_id,
is_home = 1
) %>%
# Also create corresponding away team rows
bind_rows(
tibble(
GW = fixtures_data$event,
home_team_id = fixtures_data$team_h,
away_team_id = fixtures_data$team_a
) %>%
filter(!is.na(GW)) %>%
transmute(
GW = GW,
team_id = away_team_id,
opponent_id = home_team_id,
is_home = 0
)
)
# Convert team IDs to match your internal team IDs if needed
# This depends on how your team IDs are structured compared to FPL's
# You might need to create a mapping table
return(formatted_fixtures)
}
future_fixtures <- get_fpl_fixtures()
future_fixtures
# Function to get team mapping from FPL API
get_team_mapping <- function() {
# Make API request to bootstrap-static endpoint which contains team data
response <- GET("https://fantasy.premierleague.com/api/bootstrap-static/")
# Check if request was successful
if (http_status(response)$category != "Success") {
stop("Failed to fetch bootstrap data from FPL API. Status code: ", status_code(response))
}
# Parse JSON response
bootstrap_json <- content(response, "text", encoding = "UTF-8")
bootstrap_data <- fromJSON(bootstrap_json, flatten = TRUE)
# Extract team data
team_mapping <- tibble(
team_id = bootstrap_data$teams$id,
team_name = bootstrap_data$teams$name,
team_short_name = bootstrap_data$teams$short_name
)
return(team_mapping)
}
team_mapping <- get_team_mapping()
if (exists("future_fixtures")) {
print(paste("Max GW in future_fixtures:", max(future_fixtures$GW, na.rm = TRUE)))
print("Gameweeks present in future_fixtures:")
print(table(future_fixtures$GW))
glimpse(future_fixtures)
} else {
print("future_fixtures data frame does not exist.")
}
num_previous_full_seasons <- 2 # Set this correctly
# --- End User Input ---
# 1. Determine Starting GWs (Historical and API)
#--------------------------------------------
if (!exists("alternativsammensatt") || !("GW" %in% names(alternativsammensatt))) {
stop("The 'alternativsammensatt' dataframe is missing or does not contain the 'GW' column.")
}
last_historical_gw <- max(alternativsammensatt$GW, na.rm = TRUE)
current_api_gw <- last_historical_gw - (num_previous_full_seasons * 38)
target_api_gws <- (current_api_gw + 1):(current_api_gw + antall_uker)
cat("Last Historical GW in data:", last_historical_gw, "\n")
cat("Corresponding Current API GW:", current_api_gw, "\n")
cat("Forecasting for API GWs:", paste(target_api_gws, collapse = ", "), "\n")
if (any(target_api_gws > 38)) {
cat("WARNING: Target API GWs exceed 38. Ensure 'future_fixtures' contains data for the next season if applicable.\n")
}
if (any(target_api_gws < 1)) {
stop("Calculated target API GWs are less than 1. Check 'num_previous_full_seasons' calculation.")
}
# 2. Get Fixtures for Future API Gameweeks
#--------------------------------------------
if (!exists("future_fixtures") || !all(c("GW", "team_id", "opponent_id", "is_home") %in% names(future_fixtures))) {
stop("The 'future_fixtures' dataframe is missing or does not have the required columns (GW, team_id, opponent_id, is_home). It should use API GW numbering (1-38).")
}
future_fixtures_filtered <- future_fixtures %>%
filter(GW %in% target_api_gws) %>%
mutate(across(c(team_id, opponent_id), as.integer))
if (nrow(future_fixtures_filtered) == 0) {
stop("No API fixture data found for the target API gameweeks: ", paste(target_api_gws, collapse=", "))
}
cat("Fixture data loaded for target API GWs.\n")
# 3. Prepare Base Input Data (Once per position)
#--------------------------------------------
base_input_list <- list()
all_player_metadata <- list()
for (pos in c("gk", "def", "mid", "fwd")) {
cat("\n--- Preparing base input for position:", toupper(pos), "---\n")
if (!pos %in% names(model_list)) { cat("   Skipping: Model not found for", pos, "\n"); next }
if (!pos %in% names(scaling_factors)) { cat("   Skipping: Scaling factors not found for", pos, "\n"); next }
current_model <- model_list[[pos]]
current_mu <- scaling_factors[[pos]]$mu
current_sigma <- scaling_factors[[pos]]$sigma
current_numF <- scaling_factors[[pos]]$numF
if (!exists(pos)) { cat("   Skipping: Scaled data frame '", pos, "' not found.\n"); next }
if (!exists(paste0("unscaled_", pos))) { cat("   Skipping: Unscaled data frame 'unscaled_", pos, "' not found.\n"); next }
scaled_data <- get(pos)
unscaled_data_minimal <- get(paste0("unscaled_", pos)) %>%
distinct(player_id, name, position, team, value)
all_player_metadata[[pos]] <- unscaled_data_minimal
active_players_pos <- scaled_data %>%
filter(GW == last_historical_gw) %>%
distinct(player_id, tID) %>%
mutate(across(c(player_id, tID), as.integer))
if (nrow(active_players_pos) == 0) {
cat("   No active players found for", toupper(pos), "in Historical GW", last_historical_gw, ". Skipping.\n")
next
}
base_input_data_pos <- scaled_data %>%
filter(player_id %in% active_players_pos$player_id) %>%
group_by(player_id) %>%
arrange(GW) %>%
slice_tail(n = vindu) %>%
filter(n() == vindu) %>%
ungroup()
players_with_history <- base_input_data_pos %>% distinct(player_id)
active_players_pos <- active_players_pos %>% filter(player_id %in% players_with_history$player_id)
n_forecast_pos <- nrow(active_players_pos)
if (n_forecast_pos == 0) {
cat("   No players with sufficient history (\", vindu, \"GWs) found for\", toupper(pos), \". Skipping.\n")
next
}
cat("   Base input data prepared for", n_forecast_pos, "players based on data up to Historical GW", last_historical_gw, ".\n")
num_list <- base_input_data_pos %>%
select(player_id, all_of(current_numF)) %>%
arrange(match(player_id, active_players_pos$player_id)) %>%
group_by(player_id) %>%
group_split(.keep = FALSE) %>%
lapply(as.matrix)
base_num_array_pos <- array(
unlist(num_list),
dim = c(n_forecast_pos, vindu, length(current_numF))
)
base_cat_player_id_pos <- matrix(as.integer(active_players_pos$player_id), ncol = 1)
base_cat_tID_pos <- matrix(as.integer(active_players_pos$tID), ncol = 1)
base_input_list[[pos]] <- list(
active_players = active_players_pos,
num_array = base_num_array_pos,
cat_player_id = base_cat_player_id_pos,
cat_tID = base_cat_tID_pos,
mu = current_mu,
sigma = current_sigma
)
}
all_player_metadata_df <- bind_rows(all_player_metadata) %>% distinct(player_id, .keep_all = TRUE)
# 4. Forecast Loop (Predicting for each fixture in target GWs)
#--------------------------------------------
all_fixture_forecasts_list <- list() # Store predictions PER FIXTURE
for (gw_api_to_predict in target_api_gws) {
cat("\n--- Forecasting for API GW:", gw_api_to_predict, "---\n")
future_fixtures_gw <- future_fixtures_filtered %>% filter(GW == gw_api_to_predict)
if (nrow(future_fixtures_gw) == 0) {
cat("   WARNING: No fixture data found for API GW", gw_api_to_predict, ". Skipping this GW.\n")
next
}
forecasts_this_gw_list <- list()
for (pos in names(base_input_list)) {
cat("      Forecasting position:", toupper(pos), "\n")
base_inputs <- base_input_list[[pos]]
current_model <- model_list[[pos]]
# Prepare inputs for *each fixture* this GW for active players in this position
fixture_inputs_gw_pos <- base_inputs$active_players %>%
inner_join(future_fixtures_gw, by = c("tID" = "team_id"), relationship = "many-to-many") %>% # Join players to ALL their fixtures this GW
select(player_id, tID, opponent_id = opponent_id, is_home = is_home) %>%
arrange(player_id) # Arrange by player_id to group fixtures
if (nrow(fixture_inputs_gw_pos) == 0) {
cat("         No players with fixtures found for this position in GW", gw_api_to_predict, "\n")
next
}
# Identify which players have DGWs *within this position's active players*
player_fixture_counts <- fixture_inputs_gw_pos %>% count(player_id)
dgw_players_pos <- player_fixture_counts %>% filter(n > 1) %>% pull(player_id)
sgw_players_pos <- player_fixture_counts %>% filter(n == 1) %>% pull(player_id)
cat("         Found", length(dgw_players_pos), "DGW players and", length(sgw_players_pos), "SGW players.\n")
# Prepare arrays - need to potentially duplicate base arrays for DGW players
# Find indices of players in the original base arrays
player_indices <- match(fixture_inputs_gw_pos$player_id, base_inputs$active_players$player_id)
# Replicate base arrays according to the fixture list
num_array_predict <- base_inputs$num_array[player_indices, , , drop = FALSE]
cat_player_id_predict <- base_inputs$cat_player_id[player_indices, , drop = FALSE]
cat_tID_predict <- base_inputs$cat_tID[player_indices, , drop = FALSE]
# Prepare dynamic categorical inputs (already ordered by player_id)
cat_oID_predict <- matrix(as.integer(fixture_inputs_gw_pos$opponent_id), ncol = 1)
cat_hID_predict <- matrix(as.integer(fixture_inputs_gw_pos$is_home), ncol = 1)
# Dimension check
stopifnot(
nrow(num_array_predict) == nrow(cat_player_id_predict),
nrow(num_array_predict) == nrow(cat_tID_predict),
nrow(num_array_predict) == nrow(cat_oID_predict),
nrow(num_array_predict) == nrow(cat_hID_predict),
nrow(num_array_predict) == nrow(fixture_inputs_gw_pos) # Ensure all dimensions match the number of fixtures to predict
)
# Predict for ALL fixtures at once
cat("         Running prediction for", nrow(num_array_predict) ,"fixtures...\n")
pred_future_scaled <- current_model %>% predict(
list(
input_seq = num_array_predict,
input_player_id = cat_player_id_predict,
input_tID = cat_tID_predict,
input_oID = cat_oID_predict,
input_hID = cat_hID_predict
)
)
# Store raw scaled predictions PER FIXTURE
future_preds_per_fixture <- tibble(
player_id = fixture_inputs_gw_pos$player_id,
GW = gw_api_to_predict, # API GW number
position = pos,
opponent_id = fixture_inputs_gw_pos$opponent_id,
is_home = fixture_inputs_gw_pos$is_home,
predicted_points_scaled_fixture = as.vector(pred_future_scaled)
)
forecasts_this_gw_list[[pos]] <- future_preds_per_fixture
cat("         Raw fixture forecasts stored for", nrow(future_preds_per_fixture), "fixtures.\n")
}
# Add all fixture forecasts for this GW to the main list
all_fixture_forecasts_list[[as.character(gw_api_to_predict)]] <- bind_rows(forecasts_this_gw_list)
}
# 5. Aggregate Predictions per GW, Unscale, and Finalize
#--------------------------------------------
future_forecast_df_raw_fixtures <- bind_rows(all_fixture_forecasts_list)
if (nrow(future_forecast_df_raw_fixtures) == 0) {
stop("No future fixture forecasts were generated.")
}
cat("\n--- Aggregating, Unscaling and Finalizing Forecasts ---\n")
# Aggregate scaled predictions by summing per player per GW
future_forecast_df_aggregated_scaled <- future_forecast_df_raw_fixtures %>%
group_by(player_id, GW, position) %>%
summarise(
predicted_total_points_scaled = sum(predicted_points_scaled_fixture, na.rm = TRUE),
num_fixtures = n(), # Keep track of how many fixtures were summed
# Keep first opponent/home status for display purposes (or create a combined string)
first_opponent_id = first(opponent_id),
first_is_home = first(is_home),
.groups = 'drop'
)
# Unscale the *aggregated* predictions
future_forecast_df_unscaled <- future_forecast_df_aggregated_scaled %>%
mutate(
mu = map_dbl(position, ~ scaling_factors[[.x]]$mu),
sigma = map_dbl(position, ~ scaling_factors[[.x]]$sigma),
predicted_total_points = predicted_total_points_scaled * sigma + mu,
predicted_total_points = round(predicted_total_points, 2)
) %>%
select(-predicted_total_points_scaled, -mu, -sigma)
# 6. Translate IDs to Strings
#--------------------------------------------
if (!exists("team_mapping") || !all(c("team_id", "team_name") %in% names(team_mapping))) {
stop("The 'team_mapping' dataframe is missing or does not have 'team_id' and 'team_name' columns.")
}
team_mapping <- team_mapping %>% mutate(team_id = as.integer(team_id))
future_forecast_df_final <- future_forecast_df_unscaled %>%
left_join(all_player_metadata_df, by = "player_id", suffix = c("", ".meta")) %>%
# Join opponent team name based on the *first* opponent ID
left_join(team_mapping %>% select(first_opponent_id = team_id, opponent_team_name = team_name),
by = "first_opponent_id") %>%
# Handle NO_FIXTURE case (if opponent ID was 0)
mutate(opponent_display = ifelse(first_opponent_id == 0, "NO_FIXTURE",
ifelse(num_fixtures > 1, paste0(opponent_team_name, " (DGW)"), opponent_team_name)),
is_home_display = ifelse(first_opponent_id == 0, NA_character_,
ifelse(num_fixtures > 1, paste0(first_is_home, " (DGW)"), as.character(first_is_home)))
) %>%
# Select and arrange final columns
select(
GW, # API GW
player_id,
name,
position = position,
team = team,
value = value,
opponent_display, # Shows first opponent, notes DGW
is_home_display,  # Shows first fixture home/away, notes DGW
num_fixtures,     # Number of fixtures in this GW
predicted_points = predicted_total_points
) %>%
arrange(GW, desc(predicted_points))
cat("Final forecast data frame created with team names and DGW handling.\n")
glimpse(future_forecast_df_final)
# 7. Export the Final Forecasts
#--------------------------------------------
future_filename <- paste0("Future_Forecasts_API_GW", min(target_api_gws), "_to_GW", max(target_api_gws), "_Final_DGW_Summed.csv")
write_csv(future_forecast_df_final, future_filename)
cat("Final future forecasts saved to", future_filename, "\n")
